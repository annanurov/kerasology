{"cells":[{"metadata":{},"cell_type":"markdown","source":"# =Programming Sample="},{"metadata":{},"cell_type":"markdown","source":"## CNN classifier for the MNIST dataset"},{"metadata":{},"cell_type":"markdown","source":"### Intenstions\n\nIn this notebook, we will write code to build, compile and fit a convolutional neural network (CNN) model to the MNIST dataset of images of handwritten digits.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D,  Softmax, MaxPooling2D\nfrom tensorflow.keras.preprocessing import image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![MNIST overview image](data/mnist.png)\n\n#### The MNIST dataset\n\n[MNIST dataset](http://yann.lecun.com/exdb/mnist/) consists of a training set of 60,000 handwritten digits with corresponding labels, and a test set of 10,000 images. The images have been normalised and centred. The dataset is frequently used in machine learning research, and has become a standard benchmark for image classification models. \n\n- Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n\nWe aim to construct a neural network that classifies images of handwritten digits into one of 10 classes."},{"metadata":{},"cell_type":"markdown","source":"### Load and preprocess the data"},{"metadata":{"trusted":false},"cell_type":"code","source":"mnist_data = tf.keras.datasets.mnist\n(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, preprocess the data by scaling the training and test images so their values lie in the range from 0 to 1."},{"metadata":{"trusted":false},"cell_type":"code","source":"def scale_mnist_data(train_images, test_images):\n    \"\"\"\n    m=0\n    for i in train_images:\n        for j in i:\n            for k in j:\n                if m < k: m=k\n    #print(m)\n    if m > 1.00:\n        train_images = train_images / float(m) #255.0\n        test_images = test_images / float(m) #255.0\n    \"\"\"\n    ###FASTER TO CODE:\n    return  train_images / 255.0,  test_images / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"scaled_train_images, scaled_test_images = scale_mnist_data(train_images, test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Add a dummy channel dimension\n\nscaled_train_images = scaled_train_images[..., np.newaxis]\nscaled_test_images = scaled_test_images[..., np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build the convolutional neural network model"},{"metadata":{},"cell_type":"markdown","source":"We are now ready to construct a model to fit to the data:\n\n* The model should use the `input_shape` in the function argument to set the input size in the first layer.\n* A 2D convolutional layer with a 3x3 kernel and 8 filters. Use 'SAME' zero padding and ReLU activation functions. Make sure to provide the `input_shape` keyword argument in this first layer.\n* A max pooling layer, with a 2x2 window, and default strides.\n* A flatten layer, which unrolls the input into a one-dimensional tensor.\n* Two dense hidden layers, each with 64 units and ReLU activation functions.\n* A dense output layer with 10 units and the softmax activation function."},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_model(input_shape):\n    model = Sequential ()\n    model.add(Conv2D(8, (3,3), activation='relu', padding='SAME', input_shape=input_shape))\n    model.add(MaxPooling2D(3,3))\n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model = get_model(scaled_train_images[0].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compile the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"def compile_model(model):\n    model.compile(\n        optimizer='adam', \n        loss='sparse_categorical_crossentropy', \n        ##categorical_crossentropy \n        ##sparse_categorical_crossentropy\n        metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"compile_model(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit the model to the training data"},{"metadata":{"trusted":false},"cell_type":"code","source":"def train_model(model, scaled_train_images, train_labels):\n    hisptory = model.fit(scaled_train_images, train_labels, epochs=5 )\n    return hisptory\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"history = train_model(model, scaled_train_images, train_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Plot the learning curves\n\nWe will now plot two graphs:\n- Epoch vs accuracy\n- Epoch vs loss\n\nWe will load the model history into a pandas `DataFrame` and use the `plot` method to output the required graphs."},{"metadata":{"trusted":false},"cell_type":"code","source":"frame = pd.DataFrame(history.history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"acc_plot = frame.plot(y=\"accuracy\", title=\"Accuracy vs Epochs\", legend=False)\nacc_plot.set(xlabel=\"Epochs\", ylabel=\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"acc_plot = frame.plot(y=\"loss\", title = \"Loss vs Epochs\",legend=False)\nacc_plot.set(xlabel=\"Epochs\", ylabel=\"Loss\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"def evaluate_model(model, scaled_test_images, test_labels):\n    r = model.evaluate(scaled_test_images, test_labels, verbose=2)\n    return r","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_loss, test_accuracy = evaluate_model(model, scaled_test_images, test_labels)\nprint(f\"Test loss: {test_loss}\")\nprint(f\"Test accuracy: {test_accuracy}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model predictions"},{"metadata":{"trusted":false},"cell_type":"code","source":"num_test_images = scaled_test_images.shape[0]\n\nrandom_inx = np.random.choice(num_test_images, 4)\nrandom_test_images = scaled_test_images[random_inx, ...]\nrandom_test_labels = test_labels[random_inx, ...]\n\npredictions = model.predict(random_test_images)\n\nfig, axes = plt.subplots(4, 2, figsize=(16, 12))\nfig.subplots_adjust(hspace=0.4, wspace=-0.2)\n\nfor i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):\n    axes[i, 0].imshow(np.squeeze(image))\n    axes[i, 0].get_xaxis().set_visible(False)\n    axes[i, 0].get_yaxis().set_visible(False)\n    axes[i, 0].text(10., -1.5, f'Digit {label}')\n    axes[i, 1].bar(np.arange(len(prediction)), prediction)\n    axes[i, 1].set_xticks(np.arange(len(prediction)))\n    axes[i, 1].set_title(f\"Categorical distribution. Model prediction: {np.argmax(prediction)}\")\n    \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}