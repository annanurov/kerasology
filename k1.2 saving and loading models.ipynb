{"cells":[{"metadata":{"id":"FhHJcvK8QV4Y","outputId":"dc29553c-0dbb-45f4-8b02-8c6397708c28","trusted":false},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"id":"psJljMPDQV4g"},"cell_type":"markdown","source":"***\n<a id=\"coding_tutorial_1\"></a>\n## Saving and loading model weights"},{"metadata":{"id":"I1vw5dC7QV4h"},"cell_type":"markdown","source":"#### Load and inspect CIFAR-10 dataset"},{"metadata":{"id":"WmRAfrLnQV4h"},"cell_type":"markdown","source":"The CIFAR-10 dataset consists of, in total, 60000 color images, each with one of 10 labels: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. For an introduction and a download, see [this link](https://www.cs.toronto.edu/~kriz/cifar.html)."},{"metadata":{"id":"tYaEDcT3QV4j","outputId":"c24310e6-096d-43ac-8c05-891d1f2d23e3","trusted":false},"cell_type":"code","source":"# Import the CIFAR-10 dataset and rescale the pixel values\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\nx_train = x_train / 255.0\nx_test = x_test / 255.0\n\n# Use smaller subset -- speeds things up\nx_train = x_train[:10000]\ny_train = y_train[:10000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]","execution_count":null,"outputs":[]},{"metadata":{"id":"2NFSQBPtQV4n","outputId":"523da6fb-f175-4a80-8253-c4400e447cca","trusted":false},"cell_type":"code","source":"# Plot the first 10 CIFAR-10 images\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 10, figsize=(10, 1))\nfor i in range(10):\n    ax[i].set_axis_off()\n    ax[i].imshow(x_train[i])","execution_count":null,"outputs":[]},{"metadata":{"id":"8yXDKUOLQV4r"},"cell_type":"markdown","source":"#### Introduce two useful functions"},{"metadata":{"id":"6vP4aH9fQV4s","trusted":false},"cell_type":"code","source":"# Introduce function to test model accuracy\n\ndef get_test_accuracy(model, x_test, y_test):\n    test_loss, test_acc = model.evaluate(x=x_test, y=y_test, verbose=0)\n    print('accuracy: {acc:0.3f}'.format(acc=test_acc))","execution_count":null,"outputs":[]},{"metadata":{"id":"ecZD5RluQV4w","trusted":false},"cell_type":"code","source":"# Introduce function that creates a new instance of a simple CNN\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n\ndef get_new_model():\n    model = Sequential([\n        Conv2D(filters=16, input_shape=(32, 32, 3), kernel_size=(3, 3), \n               activation='relu', name='conv_1'),\n        Conv2D(filters=8, kernel_size=(3, 3), activation='relu', name='conv_2'),\n        MaxPooling2D(pool_size=(4, 4), name='pool_1'),\n        Flatten(name='flatten'),\n        Dense(units=32, activation='relu', name='dense_1'),\n        Dense(units=10, activation='softmax', name='dense_2')\n    ])\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"_4L6ZINMQV40"},"cell_type":"markdown","source":"#### Create simple convolutional neural network classifier"},{"metadata":{"id":"gy8aByLEQV41","trusted":false},"cell_type":"code","source":"# Create an instance of the model and show model summary\nmodel = get_new_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"D0cUFG--QV44","outputId":"72bbb2f9-ae96-46bc-88a4-93d7dc35bbbd","trusted":false},"cell_type":"code","source":"# Test accuracy of the untrained model, around 10% (random)\n\nget_test_accuracy(model, x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"BKs65rmrQV47"},"cell_type":"markdown","source":"#### Train model with checkpoints"},{"metadata":{"id":"80y5otJhQV48","trusted":false},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"id":"7jHrMg2gQV4_","trusted":false},"cell_type":"code","source":"# Create Tensorflow checkpoint object\ncheckpoint_path='model_checkpoints/checkpoints' #directorry / file !!!!\ncheckpoint = ModelCheckpoint(filepath = checkpoint_path,\n                            frequency = 'epoch',\n                             save_weights_only=True,\n                            verbose = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"whLx85o8QV5C","trusted":false},"cell_type":"code","source":"# Fit model, with simple checkpoint which saves (and overwrites) model weights every epoch\nmodel.fit(x=x_train,\n         y=y_train,\n          epochs=3,\n         callbacks=[checkpoint])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"D209jNsjQV5E","trusted":false},"cell_type":"code","source":"# Have a look at what the checkpoint creates\n!dir model_checkpoints \n#unix:\n#! ls -lh model_checkpoints","execution_count":null,"outputs":[]},{"metadata":{"id":"h-pNaG0SQV5H","trusted":false},"cell_type":"code","source":"# Evaluate the performance of the trained model\nget_test_accuracy(model, x_test, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"WUfpiZPbQV5J"},"cell_type":"markdown","source":"#### Create new model, load weights"},{"metadata":{"id":"lTea2mN3QV5L","trusted":false},"cell_type":"code","source":"# Create a new instance of the (initialised) model, accuracy around 10% again\nmodel2 = get_new_model()\nget_test_accuracy(model2, x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"jek222rgQV5O","trusted":false},"cell_type":"code","source":"# Load weights -- accuracy is the same as the trained model\nmodel2.load_weights(checkpoint_path)\nget_test_accuracy(model2, x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"z1IlV3jlQV5R"},"cell_type":"markdown","source":"#### Clear directory"},{"metadata":{"id":"x8rPJLyHQV5R","trusted":false},"cell_type":"code","source":"! rm -r model_checkpoints","execution_count":null,"outputs":[]},{"metadata":{"id":"hAytIX3jQV5U"},"cell_type":"markdown","source":"***\n<a id=\"coding_tutorial_2\"></a>\n## Model saving criteria"},{"metadata":{"id":"nybq0atkQV5U"},"cell_type":"markdown","source":"#### Create more customised checkpoint"},{"metadata":{"id":"C_cRCxneQV5V","trusted":false},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"id":"241WckCvQV5X","trusted":false},"cell_type":"code","source":"# Create Tensorflow checkpoint object with epoch and batch details\n#checkpoint_5000_path='model_checkpoints_5000/checkpoints_{epoch:02d}_{batch:04d}'\ncheckpoint_path_5000='model_checkpoints_5000/checkpoints_{epoch:02d}'\ncheckpoint_5000 = ModelCheckpoint(filepath = checkpoint_path_5000,\n                                  frequency = 5000, save_weights_only=True, verbose = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ZKzsgIMjQV5b","trusted":false},"cell_type":"code","source":"# Create and fit model with checkpoint\nmodel_5000 = get_new_model()\nmodel_5000.fit(x=x_train,\n               y=y_train,\n               epochs=3,\n               validation_data=(x_test, y_test),\n               batch_size=10,\n               callbacks=[checkpoint_5000])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"wc7zjxp2QV5d","trusted":false},"cell_type":"code","source":"# Have a look at what the checkpoint creates\n#help(ModelCheckpoint)\n!dir model_checkpoints_5000\n","execution_count":null,"outputs":[]},{"metadata":{"id":"_pme6veJQV5f"},"cell_type":"markdown","source":"#### Work with model saving criteria"},{"metadata":{"id":"CjMa5HOOQV5g","trusted":false},"cell_type":"code","source":"# Use tiny training and test set -- will overfit!\n\nx_train = x_train[:100]\ny_train = y_train[:100]\nx_test = x_test[:100]\ny_test = y_test[:100]","execution_count":null,"outputs":[]},{"metadata":{"id":"sxawGcUDQV5i","trusted":false},"cell_type":"code","source":"# Create a new instance of untrained model\nmodel3=get_new_model()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"OpnNVn2sQV5l","trusted":false},"cell_type":"code","source":"# Create Tensorflow checkpoint object which monitors the validation accuracy\ncheckpoint_best_path=\"model_checkpoints_best/checkpoint\"\ncheckpoint_best = ModelCheckpoint(filepath = checkpoint_best_path,\n                                  frequency = 'epoch', save_weights_only=True,\n                                  monitor='val_accuracy',\n                                  save_best_only=True,\n                                  verbose = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Zu0lO1m_QV5o","trusted":false},"cell_type":"code","source":"# Fit the model and save only the weights with the highest validation accuracy\nhistory=model3.fit(x=x_train,y=y_train,\n                   epochs=50, validation_data=(x_test, y_test),\n                   batch_size=10,\n                   callbacks=[checkpoint_best], verbose=0)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"85DHia85QV5r","trusted":false},"cell_type":"code","source":"# Plot training and testing curves\n\nimport pandas as pd\n\ndf = pd.DataFrame(history.history)\ndf.plot(y=['accuracy', 'val_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"MKsAfSmfQV5v","trusted":false},"cell_type":"code","source":"# Inspect the checkpoint directory\n!dir model_checkpoints_best\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Xrx5i7bcQV5y","trusted":false},"cell_type":"code","source":"# Create a new model with the saved weights\nmodel4=get_new_model()\nmodel4.load_weights(checkpoint_best_path)\nget_test_accuracy(model3, x_test, y_test)\nget_test_accuracy(model4, x_test, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"bNF93Fu_QV52"},"cell_type":"markdown","source":"#### Clear directory"},{"metadata":{"id":"SerdaweWQV53","trusted":false},"cell_type":"code","source":"! rm -r model_checkpoints_5000 model_checkpoints_best","execution_count":null,"outputs":[]},{"metadata":{"id":"p2dNGwLzQV55"},"cell_type":"markdown","source":"***\n<a id=\"coding_tutorial_3\"></a>\n## Saving the entire model"},{"metadata":{"id":"e0pP6oW1QV57"},"cell_type":"markdown","source":"#### Create checkpoint that saves whole model, not just weights"},{"metadata":{"id":"S3ROR9KfQV58","trusted":false},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"id":"VvacO7lDQV5-","trusted":false},"cell_type":"code","source":"# Create Tensorflow checkpoint object\n\ncheckpoint_path = 'model_checkpoints'#this is only the name of the idrectory: saving model will create its own files \ncheckpoint = ModelCheckpoint(filepath=checkpoint_path,\n                             save_weights_only=False,\n                             frequency='epoch',\n                             verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"RhmnWVElQV6A","outputId":"23936c47-1306-4b0a-979d-af5b23b019ae","trusted":false},"cell_type":"code","source":"# Create and fit model with checkpoint\nmodel=get_new_model()\nmodel.fit(x=x_train,\n          y=y_train,\n          epochs=3,\n          callbacks=[checkpoint])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"-CGRXB0rQV6C"},"cell_type":"markdown","source":"#### Inspect what the checkpoint has created"},{"metadata":{"id":"Wtl3cHhLQV6D","outputId":"0207d0d7-c7ab-4fb8-b7fc-2638ad7fb882","trusted":false},"cell_type":"code","source":"# Have a look at what the checkpoint creates\n\n#!ls -lh model_checkpoints\n!dir model_checkpoints","execution_count":null,"outputs":[]},{"metadata":{"id":"7okHv-mqQV6F","outputId":"af75b481-5bb1-49be-d757-0e636e7ceb8a","trusted":false},"cell_type":"code","source":"# Enter variables directory\n\n#!ls -lh model_checkpoints/variables\n!dir model_checkpoints\\variables\n","execution_count":null,"outputs":[]},{"metadata":{"id":"53_Xuy0pQV6J","outputId":"c9cd03bd-3713-495c-efe2-334be29061f5","trusted":false},"cell_type":"code","source":"# Get the model's test accuracy\n\nget_test_accuracy(model, x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"4lc0c5GhQV6R"},"cell_type":"markdown","source":"#### Create new model from scratch"},{"metadata":{"id":"NsakDucMQV6S","trusted":false},"cell_type":"code","source":"# Delete model\ndel model\n","execution_count":null,"outputs":[]},{"metadata":{"id":"YvAxxOnHQV6U","trusted":false},"cell_type":"code","source":"from tensorflow.keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"id":"LXDBpAg3QV6X","outputId":"028e4e1a-b3d9-4985-f7d8-47470baa94a2","trusted":false},"cell_type":"code","source":"# Reload model from scratch\n\nmodel5=load_model(checkpoint_path)\nget_test_accuracy(model5, x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"T0-NSEAlQV6c"},"cell_type":"markdown","source":"#### Use the .h5 format to save model"},{"metadata":{"id":"nOKto4IkQV6c","trusted":false},"cell_type":"code","source":"# Save the model in .h5 format\n\nmodel.save('my_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"7C0vfEnWQV6e","outputId":"fb317852-4d16-4a87-be36-9e1c07cd1c50","trusted":false},"cell_type":"code","source":"# Inspect .h5 file\n#!ls -lh my_model.h5\n!dir my_model.h5\n","execution_count":null,"outputs":[]},{"metadata":{"id":"G2uU17ozQV6g","trusted":false},"cell_type":"code","source":"# Delete model\n\ndel model","execution_count":null,"outputs":[]},{"metadata":{"id":"B9dtUhsjQV6i","outputId":"7fa2ab9a-6a00-4b05-af0f-1142101af026","trusted":false},"cell_type":"code","source":"# Reload model from scratch\nmodel = load_model(\"my_model.h5\")\nget_test_accuracy(model, x_test, y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"-ca32hu5QV6l"},"cell_type":"markdown","source":"#### Clear directory"},{"metadata":{"id":"ftRw7KksQV6m","trusted":false},"cell_type":"code","source":"! rm -r model_checkpoints\n! rm my_model.h5","execution_count":null,"outputs":[]},{"metadata":{"id":"CIrP42vlQV6p"},"cell_type":"markdown","source":"***\n<a id=\"coding_tutorial_4\"></a>\n## Loading pre-trained Keras models"},{"metadata":{"id":"dJIEw9d_QV6q"},"cell_type":"markdown","source":"#### Import and build Keras ResNet50 model\n\nToday we'll be using the ResNet50 model designed by a team at Microsoft Research, available through Keras applications. Please see the description on the [Keras applications page](https://keras.io/applications/#resnet) for details. If you continue using it, please cite it properly! The paper it comes from is:\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. \"Deep Residual Learning for Image Recognition\", 2015.\n\nIn the coding tutorial on Coursera, this model is loaded directly from disk. On Colab, you will load the model using the Keras API."},{"metadata":{"id":"i9GUZVHiQV6q","trusted":false},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nmodel = ResNet50(weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"kRej5bQdQV6v"},"cell_type":"markdown","source":"#### Import and preprocess 3 sample images"},{"metadata":{"id":"N7_mAS06ROOG","trusted":false},"cell_type":"code","source":"# Retrieve the image files\n\n!wget -q -O lemon.jpg --no-check-certificate \"https://docs.google.com/uc?export=download&id=1JSgQ9qgi9nO9t2aGEk-zA6lzYNUT9vZJ\"\n!wget -q -O viaduct.jpg --no-check-certificate \"https://docs.google.com/uc?export=download&id=1sQzMKmyCR5Tur19lP3n1IIlEMG_o6Mct\"\n!wget -q -O water_tower.jpg --no-check-certificate \"https://docs.google.com/uc?export=download&id=1cPAQD1O6mAiMbg0fmG5HIk8OuO_BSC6J\"","execution_count":null,"outputs":[]},{"metadata":{"id":"bZ8MTLLqQV6w","trusted":false},"cell_type":"code","source":"# Import 3 sample ImageNet images\n\nfrom tensorflow.keras.preprocessing.image import load_img\n\nlemon_img = load_img('lemon.jpg', target_size=(224, 224))\nviaduct_img = load_img('viaduct.jpg', target_size=(224, 224))\nwater_tower_img = load_img('water_tower.jpg', target_size=(224, 224))","execution_count":null,"outputs":[]},{"metadata":{"id":"_aK33Lj-QV6y"},"cell_type":"markdown","source":"#### Use ResNet50 model to classify images"},{"metadata":{"id":"XQXTBltYQV6z","trusted":false},"cell_type":"code","source":"# Useful function: presents top 5 predictions and probabilities\n\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\nimport pandas as pd\n\ndef get_top_5_predictions(img):\n    x = img_to_array(img)[np.newaxis, ...]\n    x = preprocess_input(x)\n    preds = decode_predictions(model.predict(x), top=5)\n    top_preds = pd.DataFrame(columns=['prediction', 'probability'],\n                             index=np.arange(5)+1)\n    for i in range(5):\n        top_preds.loc[i+1, 'prediction'] = preds[0][i][1]\n        top_preds.loc[i+1, 'probability'] = preds[0][i][2] \n    return top_preds","execution_count":null,"outputs":[]},{"metadata":{"id":"_fAaFrecQV64"},"cell_type":"markdown","source":"##### Image 1: lemon"},{"metadata":{"id":"e3mc6ukbQV64","trusted":false},"cell_type":"code","source":"# Display image\nlemon_img\n","execution_count":null,"outputs":[]},{"metadata":{"id":"6ytQGmivQV67","trusted":false},"cell_type":"code","source":"# Display top 5 predictions\nget_top_5_predictions(lemon_img)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"84aRsXzIQV69"},"cell_type":"markdown","source":"##### Image 2: viaduct"},{"metadata":{"id":"CIUQ4SouQV6-","trusted":false},"cell_type":"code","source":"# Display image\nviaduct_img\n","execution_count":null,"outputs":[]},{"metadata":{"id":"tSy1QNxZQV7A","trusted":false},"cell_type":"code","source":"# Display top 5 predictions\nget_top_5_predictions(viaduct_img)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"TByZ1C2bQV7B"},"cell_type":"markdown","source":"##### Image 3: water tower"},{"metadata":{"id":"RhkcV3TtQV7C","trusted":false},"cell_type":"code","source":"# Display image\nwater_tower_img\n","execution_count":null,"outputs":[]},{"metadata":{"id":"pQBVCRH6QV7D","trusted":false},"cell_type":"code","source":"# Display top 5 predictions\nget_top_5_predictions(water_tower_img)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"w3k4XIb9QV7F"},"cell_type":"markdown","source":"***\n<a id=\"coding_tutorial_5\"></a>\n## Tensorflow Hub modules"},{"metadata":{"id":"VX3o8DULQV7F"},"cell_type":"markdown","source":"#### Import and build Tensorflow Hub MobileNet v1 model\n\nToday we'll be using Google's MobileNet v1 model, available on Tensorflow Hub. Please see the description on the [Tensorflow Hub page](https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4) for details on it's architecture, how it's trained, and the reference. If you continue using it, please cite it properly! The paper it comes from is:\n\nAndrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam: \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\", 2017.\n\nIn the coding tutorial on Coursera, this model is loaded directly from disk. On Colab, you will load the model from TensorFlow Hub."},{"metadata":{"id":"3IKZUe3GQV7G","trusted":false},"cell_type":"code","source":"import tensorflow_hub as hub\nfrom tensorflow.keras.models import load_model, Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"module = load_model(\"mobilenet\")\nmodel = Sequential(hub.KerasLayer(module))\nmodel.build(input_shape=[None, 160, 160, 3])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"ZizaX_mqQV7K","trusted":false},"cell_type":"code","source":"# Build Google's Mobilenet v1 model\n\nmodule_url = \"https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4\"\nmodel = Sequential([hub.KerasLayer(module_url)])\nmodel.build(input_shape=[None, 160, 160, 3])","execution_count":null,"outputs":[]},{"metadata":{"id":"ASOUEQuyQV7N"},"cell_type":"markdown","source":"#### Use MobileNet model to classify images"},{"metadata":{"id":"3d5jycF8Q6YH","trusted":false},"cell_type":"code","source":"# Retrieve the image files\n\n!wget -q -O lemon.jpg --no-check-certificate \"https://docs.google.com/uc?export=download&id=1JSgQ9qgi9nO9t2aGEk-zA6lzYNUT9vZJ\"\n!wget -q -O viaduct.jpg --no-check-certificate \"https://docs.google.com/uc?export=download&id=1sQzMKmyCR5Tur19lP3n1IIlEMG_o6Mct\"\n!wget -q -O water_tower.jpg --no-check-certificate \"https://docs.google.com/uc?export=download&id=1cPAQD1O6mAiMbg0fmG5HIk8OuO_BSC6J\"","execution_count":null,"outputs":[]},{"metadata":{"id":"W7u6LUc9QV7N","trusted":false},"cell_type":"code","source":"# Import and preprocess 3 sample ImageNet images\n\nfrom tensorflow.keras.preprocessing.image import load_img\n\nlemon_img = load_img(\"lemon.jpg\", target_size=(160, 160))\nviaduct_img = load_img(\"viaduct.jpg\", target_size=(160, 160))\nwater_tower_img = load_img(\"water_tower.jpg\", target_size=(160, 160))","execution_count":null,"outputs":[]},{"metadata":{"id":"0XLfrTUUQV7P","trusted":false},"cell_type":"code","source":"# Read in categories text file\n\nwith open('data/imagenet_categories.txt') as txt_file:\n    categories = txt_file.read().splitlines()","execution_count":null,"outputs":[]},{"metadata":{"id":"hfbCaoShQV7R","trusted":false},"cell_type":"code","source":"# Useful function: presents top 5 predictions\n\nimport pandas as pd\n\ndef get_top_5_predictions(img):\n    x = img_to_array(img)[np.newaxis, ...] / 255.0\n    preds = model.predict(x)\n    top_preds = pd.DataFrame(columns=['prediction'],\n                             index=np.arange(5)+1)\n    sorted_index = np.argsort(-preds[0])\n    for i in range(5):\n        ith_pred = categories[sorted_index[i]]\n        top_preds.loc[i+1, 'prediction'] = ith_pred\n            \n    return top_preds","execution_count":null,"outputs":[]},{"metadata":{"id":"5PQnzp0SQV7T"},"cell_type":"markdown","source":"##### Image 1: lemon"},{"metadata":{"id":"29pUkAKaQV7T","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"7X9val1IQV7V","trusted":false},"cell_type":"code","source":"get_top_5_predictions(lemon_img)","execution_count":null,"outputs":[]},{"metadata":{"id":"nq22XagQQV7Y"},"cell_type":"markdown","source":"##### Image 2: viaduct"},{"metadata":{"id":"pI0wl0ZxQV7Y","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"XKr8sPJ9QV7a","trusted":false},"cell_type":"code","source":"get_top_5_predictions(viaduct_img)","execution_count":null,"outputs":[]},{"metadata":{"id":"rj_qOPFIQV7b"},"cell_type":"markdown","source":"##### Image 3: water tower"},{"metadata":{"id":"3wjj0sBrQV7b","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"wB_nL9AAQV7d","trusted":false},"cell_type":"code","source":"get_top_5_predictions(water_tower_img)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}